{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiyanAli69/Deep-learning-lab/blob/main/DL_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0itVMPIgSqq",
        "outputId": "fec803ca-e85f-461f-b2ba-e6b181174284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xor(0,1)=1\n",
            "xor(1,1)=0\n",
            "xor(0,0)=0\n",
            "xor(1,0)=1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def unitstep(v):\n",
        "  if v>=0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def perceptron(x,w,b):\n",
        "  v=np.dot(w,x)+b\n",
        "  y=unitstep(v)\n",
        "  return y\n",
        "\n",
        "x=np.array([0,0])\n",
        "w=np.array([1,1])\n",
        "b=-1.5\n",
        "y=perceptron(x,w,b)\n",
        "#wnot=-1 bnot=0.5\n",
        "def not_logicfunction(x):\n",
        "  wnot=-1\n",
        "  bnot=0.5\n",
        "  return perceptron(x,wnot,bnot)\n",
        "\n",
        "#w1=wand1=1\n",
        "#w2=wand2=1 band=-1.5\n",
        "def and_logicfunction(x):\n",
        "  w=np.array([1,1])\n",
        "  band=-1.5\n",
        "  return perceptron(x,w,band)\n",
        "\n",
        "#w1=1,w2=1,bor=-0.5\n",
        "def or_logicfunction(x):\n",
        "  w=np.array([1,1])\n",
        "  bor=-0.5\n",
        "  return perceptron(x,w,bor)\n",
        "\n",
        "def xor_logicfunction(x):\n",
        "  y1=and_logicfunction(x)\n",
        "  y2=or_logicfunction(x)\n",
        "  y3=not_logicfunction(y1)\n",
        "  final_x=np.array([y2,y3])\n",
        "  final_x=np.array([y2,y3])\n",
        "  finaloutput=and_logicfunction(final_x)\n",
        "  return finaloutput\n",
        "\n",
        "test1=np.array([0,1])\n",
        "test2=np.array([1,1])\n",
        "test3=np.array([0,0])\n",
        "test4=np.array([1,0])\n",
        "\n",
        "print(\"xor({},{})={}\".format(0,1,xor_logicfunction(test1)))\n",
        "print(\"xor({},{})={}\".format(1,1,xor_logicfunction(test2)))\n",
        "print(\"xor({},{})={}\".format(0,0,xor_logicfunction(test3)))\n",
        "print(\"xor({},{})={}\".format(1,0,xor_logicfunction(test4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuD3usj4kg-e",
        "outputId": "5e5338e0-14d5-41aa-cb16-27a11ad293fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xor(0,1)=1\n",
            "xor(1,1)=0\n",
            "xor(0,0)=0\n",
            "xor(1,0)=1\n",
            "xor(0, 0) = 1\n",
            "xor(0, 1) = 1\n",
            "xor(1, 0) = 0\n",
            "xor(1, 1) = 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def unitstep(v):\n",
        "  if v>=0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def perceptron(x,w,b):\n",
        "  v=np.dot(w,x)+b\n",
        "  y=unitstep(v)\n",
        "  return y\n",
        "\n",
        "x=np.array([0,0])\n",
        "w=np.array([1,1])\n",
        "b=-1.5\n",
        "y=perceptron(x,w,b)\n",
        "#wnot=-1 bnot=0.5\n",
        "def not_logicfunction(x):\n",
        "  wnot=-1\n",
        "  bnot=0.5\n",
        "  return perceptron(x,wnot,bnot)\n",
        "\n",
        "#w1=wand1=1\n",
        "#w2=wand2=1 band=-1.5\n",
        "def and_logicfunction(x):\n",
        "  w=np.array([1,1])\n",
        "  band=-1.5\n",
        "  return perceptron(x,w,band)\n",
        "\n",
        "#w1=1,w2=1,bor=-0.5\n",
        "def or_logicfunction(x):\n",
        "  w=np.array([1,1])\n",
        "  bor=-0.5\n",
        "  return perceptron(x,w,bor)\n",
        "\n",
        "def xor_logicfunction(x):\n",
        "  y1=and_logicfunction(x)\n",
        "  y2=or_logicfunction(x)\n",
        "  y3=not_logicfunction(y1)\n",
        "  final_x=np.array([y2,y3])\n",
        "  final_x=np.array([y2,y3])\n",
        "  finaloutput=and_logicfunction(final_x)\n",
        "  return finaloutput\n",
        "\n",
        "test1=np.array([0,1])\n",
        "test2=np.array([1,1])\n",
        "test3=np.array([0,0])\n",
        "test4=np.array([1,0])\n",
        "\n",
        "print(\"xor({},{})={}\".format(0,1,xor_logicfunction(test1)))\n",
        "print(\"xor({},{})={}\".format(1,1,xor_logicfunction(test2)))\n",
        "print(\"xor({},{})={}\".format(0,0,xor_logicfunction(test3)))\n",
        "print(\"xor({},{})={}\".format(1,0,xor_logicfunction(test4)))\n",
        "\n",
        "def train_perceptron(training_inputs, labels, learning_rate, epochs):\n",
        "    n_features = training_inputs.shape[1]\n",
        "    weights = np.random.rand(n_features)  # Random initialization\n",
        "    bias = np.random.rand(1)[0]  # Random bias initialization\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in zip(training_inputs, labels):\n",
        "            # Calculate the prediction\n",
        "            y_pred = perceptron(x, weights, bias)\n",
        "            # Update weights and bias if the prediction is wrong\n",
        "            error = y - y_pred\n",
        "            weights += learning_rate * error * x\n",
        "            bias += learning_rate * error\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# XOR dataset\n",
        "training_inputs = np.array([[0, 0],\n",
        "                            [0, 1],\n",
        "                            [1, 0],\n",
        "                            [1, 1]])\n",
        "\n",
        "# Corresponding XOR labels\n",
        "labels = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Train the perceptron for XOR\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "weights, bias = train_perceptron(training_inputs, labels, learning_rate, epochs)\n",
        "\n",
        "# Testing the trained perceptron on XOR inputs\n",
        "for test in training_inputs:\n",
        "    print(\"xor({}, {}) = {}\".format(test[0], test[1], perceptron(test, weights, bias)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "txkpXde1qslc",
        "outputId": "151a238a-f77d-4db7-b117-e10b3dbe0985"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with SGD\n",
            "epoch 1/50 - SGD Loss: 1.1870\n",
            "epoch 2/50 - SGD Loss: 1.1043\n",
            "epoch 3/50 - SGD Loss: 1.0824\n",
            "epoch 4/50 - SGD Loss: 1.0630\n",
            "epoch 5/50 - SGD Loss: 1.0530\n",
            "epoch 6/50 - SGD Loss: 1.0419\n",
            "epoch 7/50 - SGD Loss: 1.0347\n",
            "epoch 8/50 - SGD Loss: 1.0288\n",
            "epoch 9/50 - SGD Loss: 1.0230\n",
            "epoch 10/50 - SGD Loss: 1.0167\n",
            "epoch 11/50 - SGD Loss: 1.0109\n",
            "epoch 12/50 - SGD Loss: 1.0065\n",
            "epoch 13/50 - SGD Loss: 1.0016\n",
            "epoch 14/50 - SGD Loss: 0.9951\n",
            "epoch 15/50 - SGD Loss: 0.9922\n",
            "epoch 16/50 - SGD Loss: 0.9888\n",
            "epoch 17/50 - SGD Loss: 0.9839\n",
            "epoch 18/50 - SGD Loss: 0.9804\n",
            "epoch 19/50 - SGD Loss: 0.9755\n",
            "epoch 20/50 - SGD Loss: 0.9740\n",
            "epoch 21/50 - SGD Loss: 0.9698\n",
            "epoch 22/50 - SGD Loss: 0.9645\n",
            "epoch 23/50 - SGD Loss: 0.9614\n",
            "epoch 24/50 - SGD Loss: 0.9600\n",
            "epoch 25/50 - SGD Loss: 0.9554\n",
            "epoch 26/50 - SGD Loss: 0.9538\n",
            "epoch 27/50 - SGD Loss: 0.9491\n",
            "epoch 28/50 - SGD Loss: 0.9478\n",
            "epoch 29/50 - SGD Loss: 0.9449\n",
            "epoch 30/50 - SGD Loss: 0.9400\n",
            "epoch 31/50 - SGD Loss: 0.9370\n",
            "epoch 32/50 - SGD Loss: 0.9331\n",
            "epoch 33/50 - SGD Loss: 0.9321\n",
            "epoch 34/50 - SGD Loss: 0.9248\n",
            "epoch 35/50 - SGD Loss: 0.9168\n",
            "epoch 36/50 - SGD Loss: 0.9209\n",
            "epoch 37/50 - SGD Loss: 0.9160\n",
            "epoch 38/50 - SGD Loss: 0.9124\n",
            "epoch 39/50 - SGD Loss: 0.9083\n",
            "epoch 40/50 - SGD Loss: 0.9055\n",
            "epoch 41/50 - SGD Loss: 0.9024\n",
            "epoch 42/50 - SGD Loss: 0.9004\n",
            "epoch 43/50 - SGD Loss: 0.8963\n",
            "epoch 44/50 - SGD Loss: 0.8920\n",
            "epoch 45/50 - SGD Loss: 0.8885\n",
            "epoch 46/50 - SGD Loss: 0.8853\n",
            "epoch 47/50 - SGD Loss: 0.8788\n",
            "epoch 48/50 - SGD Loss: 0.8778\n",
            "epoch 49/50 - SGD Loss: 0.8721\n",
            "epoch 50/50 - SGD Loss: 0.8701\n",
            "Training with Adam\n",
            "epoch 1/50 - Adam Loss: 1.1335\n",
            "epoch 2/50 - Adam Loss: 1.0554\n",
            "epoch 3/50 - Adam Loss: 1.0305\n",
            "epoch 4/50 - Adam Loss: 1.0170\n",
            "epoch 5/50 - Adam Loss: 0.9943\n",
            "epoch 6/50 - Adam Loss: 0.9821\n",
            "epoch 7/50 - Adam Loss: 0.9474\n",
            "epoch 8/50 - Adam Loss: 0.9268\n",
            "epoch 9/50 - Adam Loss: 0.8874\n",
            "epoch 10/50 - Adam Loss: 0.8746\n",
            "epoch 11/50 - Adam Loss: 0.8420\n",
            "epoch 12/50 - Adam Loss: 0.8181\n",
            "epoch 13/50 - Adam Loss: 0.7947\n",
            "epoch 14/50 - Adam Loss: 0.7570\n",
            "epoch 15/50 - Adam Loss: 0.7505\n",
            "epoch 16/50 - Adam Loss: 0.7467\n",
            "epoch 17/50 - Adam Loss: 0.6971\n",
            "epoch 18/50 - Adam Loss: 0.6933\n",
            "epoch 19/50 - Adam Loss: 0.6627\n",
            "epoch 20/50 - Adam Loss: 0.6744\n",
            "epoch 21/50 - Adam Loss: 0.6404\n",
            "epoch 22/50 - Adam Loss: 0.5913\n",
            "epoch 23/50 - Adam Loss: 0.5710\n",
            "epoch 24/50 - Adam Loss: 0.5565\n",
            "epoch 25/50 - Adam Loss: 0.5060\n",
            "epoch 26/50 - Adam Loss: 0.5092\n",
            "epoch 27/50 - Adam Loss: 0.5049\n",
            "epoch 28/50 - Adam Loss: 0.4630\n",
            "epoch 29/50 - Adam Loss: 0.4462\n",
            "epoch 30/50 - Adam Loss: 0.4557\n",
            "epoch 31/50 - Adam Loss: 0.4412\n",
            "epoch 32/50 - Adam Loss: 0.4325\n",
            "epoch 33/50 - Adam Loss: 0.4059\n",
            "epoch 34/50 - Adam Loss: 0.4071\n",
            "epoch 35/50 - Adam Loss: 0.4043\n",
            "epoch 36/50 - Adam Loss: 0.4078\n",
            "epoch 37/50 - Adam Loss: 0.3779\n",
            "epoch 38/50 - Adam Loss: 0.4211\n",
            "epoch 39/50 - Adam Loss: 0.3805\n",
            "epoch 40/50 - Adam Loss: 0.3586\n",
            "epoch 41/50 - Adam Loss: 0.3725\n",
            "epoch 42/50 - Adam Loss: 0.3573\n",
            "epoch 43/50 - Adam Loss: 0.3589\n",
            "epoch 44/50 - Adam Loss: 0.3656\n",
            "epoch 45/50 - Adam Loss: 0.3459\n",
            "epoch 46/50 - Adam Loss: 0.3445\n",
            "epoch 47/50 - Adam Loss: 0.3171\n",
            "epoch 48/50 - Adam Loss: 0.3155\n",
            "epoch 49/50 - Adam Loss: 0.3415\n",
            "epoch 50/50 - Adam Loss: 0.3215\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_data():\n",
        "    X = np.random.randn(1000, 10)\n",
        "    Y = np.random.randn(1000, 1)\n",
        "    return X, Y\n",
        "\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(50, activation='relu', input_shape=(10,)),\n",
        "        layers.Dense(20, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_model_with_history(model, optimizer, X, Y, batch_size, epochs, optimizer_name):\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    history = []\n",
        "    for epoch in range(epochs):\n",
        "        hist = model.fit(X, Y, batch_size=batch_size, epochs=1, verbose=0)\n",
        "        loss = hist.history['loss'][0]\n",
        "        history.append(loss)\n",
        "        print(f\"epoch {epoch + 1}/{epochs} - {optimizer_name} Loss: {loss:.4f}\")\n",
        "    return history\n",
        "\n",
        "# Create data\n",
        "X, Y = create_data()\n",
        "\n",
        "# Create models\n",
        "model_sgd = create_model()\n",
        "model_adam = create_model()\n",
        "\n",
        "# Create optimizers\n",
        "optimizer_sgd = optimizers.SGD(learning_rate=0.01)\n",
        "optimizer_adam = optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Set training parameters\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "# Train models\n",
        "print(\"Training with SGD\")\n",
        "sgd_loss = train_model_with_history(model_sgd, optimizer_sgd, X, Y, batch_size, epochs, 'SGD')\n",
        "\n",
        "print(\"Training with Adam\")\n",
        "adam_loss = train_model_with_history(model_adam, optimizer_adam, X, Y, batch_size, epochs, 'Adam')\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(range(1, epochs + 1), sgd_loss, label='SGD')\n",
        "plt.plot(range(1, epochs + 1), adam_loss, label='Adam')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e43t00l2BWx",
        "outputId": "70af8bfd-f9bf-40db-ef2f-396d295c539a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with SGD:\n",
            "Epoch 1/50, Loss: 0.9882\n",
            "Epoch 2/50, Loss: 0.9753\n",
            "Epoch 3/50, Loss: 0.9691\n",
            "Epoch 4/50, Loss: 0.9665\n",
            "Epoch 5/50, Loss: 0.9632\n",
            "Epoch 6/50, Loss: 0.9617\n",
            "Epoch 7/50, Loss: 0.9591\n",
            "Epoch 8/50, Loss: 0.9592\n",
            "Epoch 9/50, Loss: 0.9555\n",
            "Epoch 10/50, Loss: 0.9567\n",
            "Epoch 11/50, Loss: 0.9519\n",
            "Epoch 12/50, Loss: 0.9514\n",
            "Epoch 13/50, Loss: 0.9510\n",
            "Epoch 14/50, Loss: 0.9496\n",
            "Epoch 15/50, Loss: 0.9504\n",
            "Epoch 16/50, Loss: 0.9470\n",
            "Epoch 17/50, Loss: 0.9462\n",
            "Epoch 18/50, Loss: 0.9467\n",
            "Epoch 19/50, Loss: 0.9434\n",
            "Epoch 20/50, Loss: 0.9437\n",
            "Epoch 21/50, Loss: 0.9426\n",
            "Epoch 22/50, Loss: 0.9418\n",
            "Epoch 23/50, Loss: 0.9414\n",
            "Epoch 24/50, Loss: 0.9404\n",
            "Epoch 25/50, Loss: 0.9404\n",
            "Epoch 26/50, Loss: 0.9385\n",
            "Epoch 27/50, Loss: 0.9384\n",
            "Epoch 28/50, Loss: 0.9386\n",
            "Epoch 29/50, Loss: 0.9389\n",
            "Epoch 30/50, Loss: 0.9322\n",
            "Epoch 31/50, Loss: 0.9352\n",
            "Epoch 32/50, Loss: 0.9340\n",
            "Epoch 33/50, Loss: 0.9337\n",
            "Epoch 34/50, Loss: 0.9322\n",
            "Epoch 35/50, Loss: 0.9326\n",
            "Epoch 36/50, Loss: 0.9317\n",
            "Epoch 37/50, Loss: 0.9277\n",
            "Epoch 38/50, Loss: 0.9308\n",
            "Epoch 39/50, Loss: 0.9297\n",
            "Epoch 40/50, Loss: 0.9295\n",
            "Epoch 41/50, Loss: 0.9295\n",
            "Epoch 42/50, Loss: 0.9282\n",
            "Epoch 43/50, Loss: 0.9268\n",
            "Epoch 44/50, Loss: 0.9236\n",
            "Epoch 45/50, Loss: 0.9265\n",
            "Epoch 46/50, Loss: 0.9248\n",
            "Epoch 47/50, Loss: 0.9252\n",
            "Epoch 48/50, Loss: 0.9235\n",
            "Epoch 49/50, Loss: 0.9216\n",
            "Epoch 50/50, Loss: 0.9211\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 34ms/step - accuracy: 0.8905 - loss: 0.3511 - val_accuracy: 0.9817 - val_loss: 0.0540\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 35ms/step - accuracy: 0.9856 - loss: 0.0472 - val_accuracy: 0.9868 - val_loss: 0.0386\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 34ms/step - accuracy: 0.9902 - loss: 0.0311 - val_accuracy: 0.9909 - val_loss: 0.0279\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 34ms/step - accuracy: 0.9927 - loss: 0.0246 - val_accuracy: 0.9872 - val_loss: 0.0411\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 36ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.9909 - val_loss: 0.0291\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.9923 - val_loss: 0.0282\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 33ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9902 - val_loss: 0.0365\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 35ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9891 - val_loss: 0.0452\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 34ms/step - accuracy: 0.9967 - loss: 0.0103 - val_accuracy: 0.9930 - val_loss: 0.0268\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 33ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9924 - val_loss: 0.0278\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0359\n",
            "Test accuracy: 0.9923999905586243\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'matplotlib' has no attribute 'plot'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b53ebe33c93b>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {test_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    227\u001b[0m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models,optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_data():\n",
        "  X=np.random.randn(1000,10)\n",
        "  y=np.random.randn(1000,1)\n",
        "  return X,y\n",
        "\n",
        "def create_model():\n",
        "  model=models.Sequential([\n",
        "      layers.Dense(10,activation=\"relu\",input_shape=(10,)),\n",
        "      layers.Dense(20,activation=\"relu\"),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def train_model_with_history(model,optimizer,X,y,batch_size,epochs,optimizer_name):\n",
        "  model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
        "  history=[]\n",
        "  for epoch in range(epochs):\n",
        "    hist=model.fit(X,y,batch_size=batch_size,epochs=1,verbose=0)\n",
        "    loss=hist.history['loss'][0]\n",
        "    history.append(loss)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
        "  return history\n",
        "\n",
        "X,y=create_data()\n",
        "model_sgd=create_model()\n",
        "model_adam=create_model()\n",
        "\n",
        "optimizer_sgd=optimizers.SGD(learning_rate=0.01)\n",
        "optimizer_adam=optimizers.Adam(learning_rate=0.01)\n",
        "epochs=50\n",
        "batch_size=32\n",
        "\n",
        "print(\"\\nTraining with SGD:\")\n",
        "loss_sgd=train_model_with_history(model_sgd,optimizer_sgd,X,y,batch_size,epochs,\"SGD\")\n",
        "\n",
        "#IMPORTING NECESSARY LBRARIES\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib as plt\n",
        "#load and preprocess the mnist dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data( )\n",
        "train_images= train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from functools import partial\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "(train_images,train_labels),(test_images,test_labels)=datasets.mnist.load_data()\n",
        "train_images=train_images.reshape((train_images.shape[0],28,28,1)).astype('float32')/255\n",
        "test_images=test_images.reshape((test_images.shape[0],28,28,1)).astype('float32')/255\n",
        "DefaultConv2D=partial(keras.layers.Conv2D,kernel_size=3,strides=1,padding=\"SAME\",use_bias=False)\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self,filters,strides=1,activation=\"relu\",**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation=keras.activations.get(activation)\n",
        "        self.main_layers=[DefaultConv2D(filters,strides=strides),keras.layers.BatchNormalization(),self.activation,\n",
        "                         DefaultConv2D(filters),\n",
        "                         keras.layers.BatchNormalization()]\n",
        "        self.skip_layers=[]\n",
        "        if strides>1:\n",
        "            self.skip_layers=[DefaultConv2D(filters,kernel_size=1,strides=strides),keras.layers.BatchNormalization()]\n",
        "    def call(self,inputs):\n",
        "        Z=inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z=layer(Z)\n",
        "        skip_Z=inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z=layer(skip_Z)\n",
        "        return self.activation(Z+skip_Z)\n",
        "model=keras.models.Sequential()\n",
        "model.add(DefaultConv2D(64,kernel_size=7,strides=2,input_shape=[28,28,1]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3,strides=2,padding=\"same\"))\n",
        "prev_filters=64\n",
        "for filters in [64]*3+[128]*2+[256]*2+[512]*2:\n",
        "    strides=1 if filters==prev_filters else 2\n",
        "    model.add(ResidualUnit(filters,strides=strides))\n",
        "    prev_filters=filters\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "aJNP18LtvawN",
        "outputId": "365d1f15-6f22-4c53-8c52-a06793403e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit (\u001b[38;5;33mResidualUnit\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m74,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_1 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m74,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_2 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m74,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_3 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m230,912\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_4 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m295,936\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_5 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m920,576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_6 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,181,696\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_7 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m3,676,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_8 (\u001b[38;5;33mResidualUnit\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m4,722,688\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">230,912</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">920,576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,676,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ residual_unit_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,722,688</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,259,210\u001b[0m (42.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,259,210</span> (42.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,249,354\u001b[0m (42.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,249,354</span> (42.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,856\u001b[0m (38.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,856</span> (38.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab-patches\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "model=torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "COCO_INSTANCE_CATEGORY_NAMES=[\n",
        "    '__background__','person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "def detect_objects(image_path,confidence_threshold=0.5):\n",
        "  image = cv2.imread(image_path)\n",
        "  if image is None:\n",
        "    print(f\"Error:could not load image from {image_path}. Please check the file path and ensure the image exists.\")\n",
        "    return None\n",
        "\n",
        "  original_image=image.copy()\n",
        ""
      ],
      "metadata": {
        "id": "Y1fw0tLpw49g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+UA8SgcXMeXJdZxpR3BYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}